{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Statistical Learning, Lab 4.5\n",
    "\n",
    "# K-Nearest Neighbours\n",
    "\n",
    "\n",
    "We will now perform a KNN classification analysis on the `Smarket` data set, trying to predict `Direction` using `Lag1` and `Lag2`. We again use the `sklearn` library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from islpy import datasets, utils, lmplots\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smarket = datasets.Smarket()\n",
    "smarket.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the observations before 2005 as the training sample and the later predictions as the test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = smarket[smarket.Year < 2005][['Lag1', 'Lag2']]\n",
    "Y_train = smarket[smarket.Year < 2005]['Direction']\n",
    "x_test = smarket[smarket.Year == 2005][['Lag1', 'Lag2']]\n",
    "Y_test = smarket[smarket.Year == 2005]['Direction']\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first look at a KNN classifier with $k=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(1)\n",
    "knn1_fit = knn1.fit(x_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn1_fit.predict(x_test)\n",
    "confusion_matrix(pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are rather poor: only about 50% of respones are predicted correctly, not any better than random chance.\n",
    "\n",
    "Remember that $k=1$ is a model with high flexibility. So we expect low bias and high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise the KNN classifier with $k=1$. We use the same utility functions as in the previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x_test['Lag1']\n",
    "x2 = x_test['Lag2']\n",
    "ax = sns.scatterplot(x=x1, y=x2, hue=Y_test)\n",
    "ax = utils.plot_decision_contour(x1, x2, knn1_fit.predict_proba, ax=ax)\n",
    "ax = utils.plot_decision_boundaries(x1, x2, knn1_fit.predict_proba, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try a KNN classifier with $k=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(3)\n",
    "knn3_fit = knn3.fit(x_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn3_fit.predict(x_test)\n",
    "confusion_matrix(pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are still poor. It turns out increasing $k$ further does not improve the situation. Feel free to explore! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise the KNN classifier with $k=3$. We use the same utility functions as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x_test['Lag1']\n",
    "x2 = x_test['Lag2']\n",
    "ax = sns.scatterplot(x=x1, y=x2, hue=Y_test)\n",
    "ax = utils.plot_decision_contour(x1, x2, knn3_fit.predict_proba, ax=ax)\n",
    "ax = utils.plot_decision_boundaries(x1, x2, knn3_fit.predict_proba, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular problem, out of all the methods we tried so far, QDA seems to perform best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
