{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Statistical Learning, Lab 4.3\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "\n",
    "\n",
    "We will now perform a linear discriminant analysis (LDA) non the `Smarket` data set, trying to predict `Direction` using `Lag1` and `Lag2`. We go beyond the now familiar `statsmodels` library and use the `sklearn` library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from islpy import datasets, utils, lmplots\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smarket = datasets.Smarket()\n",
    "smarket.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the observations before 2005 as the training sample and the later predictions as the test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = smarket[smarket.Year < 2005][['Lag1', 'Lag2']]\n",
    "Y_train = smarket[smarket.Year < 2005]['Direction']\n",
    "X_test = smarket[smarket.Year == 2005][['Lag1', 'Lag2']]\n",
    "Y_test = smarket[smarket.Year == 2005]['Direction']\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform an LDA fit on the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda_fit = lda.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda.priors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output indicates that $\\hat{\\pi}_1 = 0.492$ and $\\hat{\\pi}_2 = 0.508$. That is, 49.2% of the training observations correspond to days when the marked went down.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = pd.DataFrame(lda_fit.means_, index=('Down', 'UP'), columns=('Lag1', 'Lag2'))\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reported *means* are the average of each predictor in each class.\n",
    "\n",
    "We can read off the relation of the predictors to the market direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_fit.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $-0.0554\\times\\text{Lag1} - 0.0443\\times\\text{Lag2}$ is large the market is predicted to go up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the performance of the classifier on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lda_fit.predict(X_test)\n",
    "confusion_matrix(pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this *exactly* replicates the results from the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following summary report also confirms the agreement with the logistic regression. In particular the 58% precision when predicting `Up`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `utils` module from the `isply` library provides some utility functions to plot decision contours and boundaries.\n",
    "\n",
    "They require a callable (function, method) that properly determines the probabilities for the two dimensional range specified by two predictor arrays. They only work out of the box when the model has exactly the predictors specified. Otherwise users have to supply a callable that properly marginalises the other predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first overlay the $P=0.5$ decision contour on a scatter plot. This is the default behaviour of `utils.plot_decision_contour()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=X_train['Lag1'], y=X_train['Lag2'], hue=Y_train)\n",
    "ax = utils.plot_decision_contour(X_train['Lag1'], X_train['Lag2'],\n",
    "                                 lda_fit.predict_proba, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also overlay more contours by specifying the `levels` keyword argument. A value of `None` uses the automatic configuration from `matplotlib`'s `contour()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=X_train['Lag1'], y=X_train['Lag2'], hue=Y_train)\n",
    "ax = utils.plot_decision_contour(X_train['Lag1'], X_train['Lag2'],\n",
    "                                 lda_fit.predict_proba, ax=ax, \n",
    "                                 levels=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose the category (class) the probabilities refer to (default: $0$). Note the change in the contour annotations, they are now reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=X_train['Lag1'], y=X_train['Lag2'], hue=Y_train)\n",
    "ax = utils.plot_decision_contour(X_train['Lag1'], X_train['Lag2'],\n",
    "                                 lda_fit.predict_proba, ax=ax, \n",
    "                                 levels=None, category=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `plot_decision_boundaries()` function identifies the areas where a particular class probability is highest and overlays a coloured shade accordingly. This function works out of the box for multiple *response* classes. But the marginalisation restriction applies if there are more than two *predictors*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=X_train['Lag1'], y=X_train['Lag2'], hue=Y_train)\n",
    "ax = utils.plot_decision_boundaries(X_train['Lag1'], X_train['Lag2'],\n",
    "                                   lda_fit.predict_proba, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=X_train['Lag1'], y=X_train['Lag2'], hue=Y_train)\n",
    "ax = utils.plot_decision_contour(X_train['Lag1'], X_train['Lag2'],\n",
    "                                 lda_fit.predict_proba, ax=ax)\n",
    "ax = utils.plot_decision_boundaries(X_train['Lag1'], X_train['Lag2'],\n",
    "                                   lda_fit.predict_proba, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
