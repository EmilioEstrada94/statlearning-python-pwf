{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Statistical Learning, Lab 4.6\n",
    "\n",
    "# Caravan Insurance Data\n",
    "\n",
    "\n",
    "We will now perform a classification analysis on the `Caravan` data set, trying to predict `Purchase`, which indicates whether an individual purchases a caravan insurance policy.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from islpy import datasets, utils, lmplots\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(datasets.Caravan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caravan = datasets.Caravan()\n",
    "caravan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set only 6% of customers purchased an insurance policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caravan['Purchase'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data set in a training and a test data set, using the first 1000 observation as test data and the rest as training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = caravan[:1000]\n",
    "x_test = test[caravan.columns.drop('Purchase')]\n",
    "y_test = test['Purchase']\n",
    "train = caravan[1000:]\n",
    "x_train = train[caravan.columns.drop('Purchase')]\n",
    "y_train = train['Purchase']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN classifier relies on the distances between the predictors. This raises the question what the proper distances are. If we measured everything in the same units (say, metres) that would not be an issue. \n",
    "\n",
    "But we are often faced with data sets containing predictors such as `income` (measured in thousands of dollars) and `age` (measured in years).\n",
    "\n",
    "Intuitively, we know that a difference of 50 years is more important than an income difference of $1000.  \n",
    "\n",
    "The computer does not know that, though. We therefore have to *normalise* our data.\n",
    "\n",
    "We use the `StandardScaler` from `sklearn` and train it on the training data set. \n",
    "\n",
    "It is *very important* to use the *same* scaling on the training and test data, just like with any other model fit. It does not matter whether the scaling is determined from the training data or the full data set, though. All that matters is that the same scaling is applied to both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(x_train[x_train.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(scaler.transform(x_train[x_train.columns]), columns=x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test[x_test.columns]), columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the training and test data properly scaled, we are now ready to fit a KNN classifier. \n",
    "\n",
    "We first look at a KNN classifier with $k=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred != y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred != 'No').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error rate is 12%, which at first seems quite good. But keep in mind the low prior probability of `Purchase`. We can get the test error rate down to ~8% by always predicting `No`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(pred, y_test)\n",
    "print(cm)\n",
    "yes_pred_rate = cm[1, 1] /(cm[1, 0] + cm[1, 1])\n",
    "print(f\"Correct prediction for 'Yes': {100*yes_pred_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct prediction rate for customers who *did* buy insurance is about double the prior probability!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see whether we can further improve this with different values of $k$. We first try a KNN classifier with $k=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(3).fit(x_train, y_train)\n",
    "\n",
    "pred = knn3.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(pred, y_test)\n",
    "print(cm)\n",
    "yes_pred_rate = cm[1, 1] /(cm[1, 0] + cm[1, 1])\n",
    "print(f\"Correct prediction for 'Yes': {100*yes_pred_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN with $k=3$ was an improvement. We now try a KNN classifier with $k=5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn5 = KNeighborsClassifier(5).fit(x_train, y_train)\n",
    "\n",
    "pred = knn5.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(pred, y_test)\n",
    "print(cm)\n",
    "yes_pred_rate = cm[1, 1] /(cm[1, 0] + cm[1, 1])\n",
    "print(f\"Correct prediction for 'Yes': {100*yes_pred_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN classifier with $k=5$ performs best so far, certainly better than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try a logistic regression for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lr = patsy.dmatrix('+'.join(x_train.columns), x_train, return_type='dataframe')\n",
    "y_train_lr = (y_train == 'Yes').values\n",
    "x_test_lr = patsy.dmatrix('+'.join(x_test.columns), x_test, return_type='dataframe')\n",
    "y_test_lr = (y_test == 'Yes').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sm.GLM(y_train_lr, x_train_lr, family=sm.families.Binomial()).fit()\n",
    "probs = lm.predict(x_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = probs > 0.5\n",
    "\n",
    "cm = confusion_matrix(pred, y_test_lr)\n",
    "print(cm)\n",
    "yes_pred_rate = cm[1, 1] /(cm[1, 0] + cm[1, 1])\n",
    "print(f\"Correct prediction for 'Yes': {100*yes_pred_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't seem to work well. We predict 7 purchases and *all* of them are wrong!\n",
    "\n",
    "But we don't have to choose our *working point* at 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = probs > 0.25\n",
    "\n",
    "cm = confusion_matrix(pred, y_test_lr)\n",
    "print(cm)\n",
    "yes_pred_rate = cm[1, 1] /(cm[1, 0] + cm[1, 1])\n",
    "print(f\"Correct prediction for 'Yes': {100*yes_pred_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works much better -- we are right for 33% predictions of `Yes`. That is about five times better than random guessing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
