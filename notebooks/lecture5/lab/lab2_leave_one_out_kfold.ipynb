{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Statistical Learning, Lab 5.2\n",
    "\n",
    "# Leave-One-Out & $k$-Fold Cross Validation\n",
    "\n",
    "We will use the leave-one-out (LOOCV) and $k$-fold cross validation approaches to evaluate the test error rates from various linear models on the `Auto` data set.\n",
    "\n",
    "We will use the linear models and tools from the `sklearn` library in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from islpwf import datasets, utils, lmplots\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the data set and create the linear model `mpg~horsepower`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = datasets.Auto()\n",
    "x = auto[['horsepower']]\n",
    "y = auto['mpg']\n",
    "model = skl_lm.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave-One-Out\n",
    "\n",
    "The LOOCV can be automated with `sklearn`'s `LeaveOneOut()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loocv = LeaveOneOut()\n",
    "cv = loocv.split(x)\n",
    "scores = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Folds: {len(scores)}, MSE: {np.mean(np.abs(scores)):.2f}, STD: {np.std(scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or using `sklearn`'s `KFold` with $k = n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=auto.shape[0], random_state=None, shuffle=False)\n",
    "scores = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Folds: {len(scores)}, MSE: {np.mean(np.abs(scores)):.2f}, STD: {np.std(scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $k$-Fold\n",
    "\n",
    "We evaluate the MSE for ten different polynomial models using $k$-fold cross validation with $k = 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for degree in range(1, 11):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    x_train = poly.fit_transform(x)\n",
    "    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    scores = cross_val_score(model, x_train, y, scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "    errors.append(np.mean(np.abs(scores)))\n",
    "    print(f'Degree: {degree:2d}, MSE: {errors[-1]:.2f}')\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Technical Note: Mixing Libraries\n",
    "\n",
    "We now address a common technical problem. The `sklearn` library provides many useful functions, like `KFold()` and so on. However, the reports on the linear regression are somewhat lacking. We therefore might prefer to fit our models using `statsmodels` but still use the facilities from `sklearn`.\n",
    "\n",
    "Unfortunately, this can't be done directly because `sklearn` expects a certain behaviour from the models passed to its functions. This situation comes up quite often in the Python ecosystem.\n",
    "\n",
    "The solution is to *wrap* the types from one library in an *interface* that makes them usable in another. If the involved types contain the necessary information this is always possible.\n",
    "\n",
    "For the particular problem mentioned above, the `islpwf.utils` library provides the `SMWrapper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.SMWrapper(sm.OLS)\n",
    "\n",
    "degree = 4\n",
    "poly = PolynomialFeatures(degree=degree)\n",
    "x_train = poly.fit_transform(x)\n",
    "model.fit(x_train, y)\n",
    "model.results_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(model, x_train, y, scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "print(f'Degree: {degree:2d}, MSE: {np.mean(np.abs(scores)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
