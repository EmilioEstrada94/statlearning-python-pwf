{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Statistical Learning, Lab 2.2\n",
    "\n",
    "# Data Access: Introduction to Pandas & ISLPy\n",
    "\n",
    "Pandas is the Python library of choice for accessing and manipulating data sets. It provides I/O in various file formats and a powerful interface to data sets. \n",
    "\n",
    "You can always to refer to the latest [documentation](https://pandas.pydata.org/pandas-docs/stable/index.html). You should work through the excellent [10 minutes to pandas tutorial](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) if you have not done so already. This will likely take more than 10 minutes, though.\n",
    "\n",
    "Here we will only review some basic operations to get us started. More features will be\n",
    "introduced in later labs when the need arises. We will also introduce the `islpwf` library that provides efficient access to the data sets used in this course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is conventionally imported like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need NumPy and the os module (for file path manipulation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data into Pandas\n",
    "\n",
    "When we load data into pandas it will create a data frame. \n",
    "Data frames are the core structure of pandas. We use data frames to access and manipulate data sets. You can think of a pandas data frame as a table or spreadsheet. Typically, the\n",
    "rows are the observations in a data set and the columns are the variables (features).\n",
    "\n",
    "Pandas can load data from a [variety of file formats](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `Auto` dataset csv file into pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dir = '../../datasets'\n",
    "auto_path = os.path.join(datasets_dir, 'Auto.csv')\n",
    "df = pd.read_csv(auto_path)\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the 'Khan' data set file into pandas. This file has *many* columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this load only the training features\n",
    "khan_path = os.path.join(datasets_dir, 'Khan_xtrain.csv')\n",
    "df = pd.read_csv(khan_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ISLPy Library\n",
    "\n",
    "In order to speed things up and removing the need to set the correct file paths, we provide the `islpwf` library. It facilitates access to the data sets used in this course and loads the larger data sets a little faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the `Khan` data set using the `islpwf.dataset` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from islpwf import datasets\n",
    "# conveniently loads the entire data set\n",
    "xtrain, ytrain, xtest, ytest = datasets.Khan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get help about any data set in the `islpwf.datasets` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(datasets.Khan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or for the whole module, as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following examples assume the `Auto` data set, so we reload it through the `islpwf.datasets` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(datasets.Auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets.Auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting, Selecting & Rearranging Data\n",
    "\n",
    "The data in data in data frames can be accessed, selected and rearranged in various ways. We explore a few of them on the `Auto` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()  # the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()  # the last five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)  # the first two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(11)  # the last 11 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()  # produce an overview of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = df['mpg']  # we can use the column names as keys\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(c)  # a data frame column is a pandas series object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can ask for column properties\n",
    "print(df['mpg'].median(), df['mpg'].quantile(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mpg.head()  # we can also use column names like attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()  # all column names/keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df[['mpg', 'name']]  # we can select multiple columns\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[3:5]  # we can select rows by indexing & slicing (just like python lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[3:5][['mpg', 'name']]  # the selections methods can be combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create a numpy array\n",
    "x = df[['mpg', 'weight', 'acceleration']].to_numpy()\n",
    "x[2:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.cylinders > 4) & (df.mpg > 30)]  # we can make selection cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T  # transpose of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort rows by values in a column\n",
    "df.sort_values(by='mpg', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 2:4]  # use the iloc property for numpy style indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 2:4].to_numpy()  # we can convert to raw numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column and index names\n",
    "\n",
    "It is often useful to access and manipulate the column and row names of a data frame. In particular, we often want to use a specific column as a row index or name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns  # access the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.values  # access the row indices or names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'cylinders': 'pistons', 'name': 'model'},\n",
    "          axis='columns', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('model', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
