{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "#### Introduction to Statistical Learning, Lab 11.2\n",
    "\n",
    "# Classifier Evaluation Example\n",
    "\n",
    "We use the PyTorch library:\n",
    " \n",
    "  - PyTorch [homepage](https://pytorch.org/)\n",
    "  - PyTorch [documentation](https://pytorch.org/docs/stable/index.html)\n",
    "\n",
    "In this example we evaluate the multi-class classifier we created in Training Example 1.  \n",
    "We will use the same approach to create and read the data.  However, the data file used\n",
    "for evaluation will be newly generated, guaranteeing that we are not using any data\n",
    "used in the training.\n",
    "\n",
    "As a reminder: the function `truth_labels_unit_circle` in the `dataprovider` module \n",
    "defines three classes for the (x1, x2) tuples:\n",
    "\n",
    " 1. points outside the unit circle `r = sqrt(x1*x1 + x2*x2) >= 1` (this is considered 'background')\n",
    " 2. points in the unit circle with `x2 <= 0.0` (this is considered 'signal 1')\n",
    " 3. points in the unit circle with `x2 > 0.0` (this is considered 'signal 2')\n",
    " \n",
    "The truth labels are therefore one-hot vectors of dimension 3.  The `dataprovider` \n",
    "dynamically generates the truth labels using the above definition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "#### Setup\n",
    "Import the required modules and make sure our (and only our!) modules are reloaded \n",
    "before code execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%aimport dataprovider, classification\n",
    "%autoreload 1\n",
    "\n",
    "# framework modules\n",
    "import torch\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# our modules\n",
    "import dataprovider as dp\n",
    "import classification as cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "#### Data Sets\n",
    "Here we generate a binary file with a data set for evaluation and provide the corresponding \n",
    "PyTorch data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_file_path = './evaluation_data.bin'\n",
    "dp.generate_data(data_file_path, force=False)\n",
    "num_events = 20000\n",
    "evaluation_events = dp.events(data_file_path, evt_max=num_events)\n",
    "evaluation_dataset = cl.LabeledDataset(evaluation_events,\n",
    "                                     var_generator=dp.event_to_values,\n",
    "                                     label_generator=dp.truth_labels_unit_circle)\n",
    "xs, ys_true = evaluation_dataset[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Run the Trained Classifier\n",
    "\n",
    "We construct the classifier and load the weights produced in Training Example 1.\n",
    "Next we run the classifier on the entire dataset. Not that we do this with auto \n",
    "gradient following turned off.  This is faster and we do not need the gradient\n",
    "tree for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier_nn = cl.ClassifierNN(layout=(2, 5, 7, 3))\n",
    "weight_file_path = 'classifier_weights_example1_2x5x7x3.pt'\n",
    "classifier_nn.load_state_dict(torch.load(weight_file_path))\n",
    "classifier_nn.eval()\n",
    "with torch.no_grad():\n",
    "    ys_pred = classifier_nn(xs)\n",
    "    \n",
    "print('Classfified', ys_pred.size()[0], 'events into', ys_pred.size()[1], 'classes.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "#### ROC Curves\n",
    "ROC (Receiver Operating Characteristic) curves are the ML community's version\n",
    "of the background suppression versus efficiency plots we are used to in HEP.\n",
    "In fact they are almost exactly the same.\n",
    "\n",
    "In a ROC curve the the *true positive rate* if plotted versus the *false positive rate*.\n",
    "\n",
    "The *true positive rate* is the fraction of true target class instances identified as such, ie. \n",
    "the *efficiency*.\n",
    "\n",
    "The *false positive rate* is the fraction of true background events identified as such, ie.\n",
    " *1 - background suppression*.\n",
    "\n",
    "The rates are computed by scanning the classifier output \n",
    "in the interval `[0, 1]`. We do not have to write the code for this \n",
    "scan ourselves.  Instead we use the `metric` facilities of `sklearn`.\n",
    "\n",
    "AUC is simply the area under the ROC curve in the interval `[0, 1]`. \n",
    "An AUC of 1 is ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_labels = {0 : 'background', 1 : 'signal 1', 2: 'signal 2'}\n",
    "fpr, tpr, thresh, area = dict(), dict(), dict(), dict()\n",
    "for i in range(3):\n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(ys_true[:,i], ys_pred[:,i])\n",
    "    area[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure()\n",
    "plt.title('ROC Curves')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "for i in range(3):\n",
    "    plt.plot(fpr[i], tpr[i], label='{} AUC: {:.4f}'.format(plot_labels[i], area[i]))\n",
    "\n",
    "plt.plot(thresh[2][1:], thresh[2][1:], '--', label='threshold')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('ROC Curves Zoom')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlim((-0.01, 0.2))\n",
    "plt.ylim((0.8, 1.01))\n",
    "for i in range(3):\n",
    "    plt.plot(fpr[i], tpr[i], label='{} AUC: {:.4f}'.format(plot_labels[i], area[i]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "#### Background Suppression Versus Efficiency\n",
    "\n",
    "We now plot the same data in the more familiar \n",
    "fashion of background suppression versus efficiency.\n",
    "\n",
    "Here (and in the ROC section above) the *background* is the collection of events that\n",
    "are a different class instance than the class label considered. For example, the background for \n",
    "*signal 1* is all events where the true class is either *background* or *signal 2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eff = tpr\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Background Supp. vs. Efficiency')\n",
    "plt.xlabel('Efficiency')\n",
    "plt.ylabel('Background Suppression')\n",
    "for i in range(3):\n",
    "    plt.plot(eff[i], 1.0 - fpr[i], label='{} AUC: {:.4f}'.format(plot_labels[i], area[i]))\n",
    "plt.plot(thresh[2][1:], 1.0 - thresh[2][1:], '--', label='threshold')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Background Supp. vs. Efficiency Zoom')\n",
    "plt.xlabel('Efficiency')\n",
    "plt.ylabel('Background Suppression')\n",
    "plt.xlim((0.8, 1.01))\n",
    "plt.ylim((0.8, 1.01))\n",
    "for i in range(3):\n",
    "    plt.plot(eff[i], 1.0 - fpr[i], label='{} AUC: {:.4f}'.format(plot_labels[i], area[i]))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
