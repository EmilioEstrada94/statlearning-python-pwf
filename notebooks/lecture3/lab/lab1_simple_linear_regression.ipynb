{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Statistical Learning, Lab 3.1\n",
    "\n",
    "# Simple Linear Regression\n",
    "\n",
    "In the Python environment the most popular libraries for model fitting (and therefore linear regression) *sklearn* and *statsmodels*. The statsmodels library provides a R-style formula-based interface. We will mostly use this interface because it provides more flexibility and better parameter reporting. This has the additional advantage that it maps quite well onto the examples in the ISLR book.  \n",
    "\n",
    "\n",
    "  - [statsmodels documentation](https://www.statsmodels.org/stable/)\n",
    "  - [statsmodels formula interface](https://www.statsmodels.org/stable/example_formulas.html)\n",
    "  - [the formula mini language](https://patsy.readthedocs.io/en/latest/formulas.html#the-formula-language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from islpy import datasets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set\n",
    "\n",
    "We use the `Boston` data set to demonstrate simple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.Boston()\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Specification\n",
    "\n",
    "The `smf.ols()` function builds a statistical *model* prepared for fitting with *ordinary least squares* (ols). This is the type of fit explained in detail in the lecture.\n",
    "\n",
    "The formula `medv~lstat` means we are using `lstat` as our predictor and `medv` as our dependent variable:\n",
    "\n",
    "$$ \\mathrm{medv} = \\beta_0 + \\beta_1 \\mathrm{lstat} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula='medv~lstat', data=boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the Model\n",
    "\n",
    "We *fit* the model to the data by calling the `fit()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Result Summary\n",
    "\n",
    "We can get a comprehensive summary using the `summary()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specific Summary Tables\n",
    "\n",
    "We can also select a specific table from the summary. For example the fitted coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Result Parameters\n",
    "\n",
    "Or we can retrieve only the fitted parameters ($\\beta_0$ = *intercept*, $\\beta_1$ = *lstat*) as a pandas series using the `params` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Intervals\n",
    "\n",
    "The 95% confidence intervals for the coefficients can be retrieved via the `conf_int()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions\n",
    "\n",
    "The purpose of fitting a model is to make predictions from as of yet unobserved predictors in the future. We use the `predict()` method to do that. Note that the predictor data set must provide all keys (column names) used in the formula. In practice this will almost always be a pandas data frame with the required columns. But any `dict`-like object with the required keys will work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.predict({'lstat': [5, 10, 15]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction with Confidence and Prediction Intervals\n",
    "\n",
    "In case we need confidence and/or prediction intervals we use the `get_prediction()` method and extract a summary data frame from the result with `summary_frame()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_fit.get_prediction({'lstat': [5, 10, 15]})\n",
    "pred.summary_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mean_ci` columns are the confidence interval limits and the `obs_ci` columns are the prediction interval limits.\n",
    "\n",
    "For instance, the 95% confidence interval associated with an `lstat` value of 10 is (24.47, 25.63), and the 95% prediction interval is (12.83, 37.28). As expected, they are both centred around the same point, the predicted value 25.05, but the prediction interval is substantially wider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the Fit Results\n",
    "\n",
    "Our goal is to make a graph with a scatter plot and overlay the line resulting from the fit. There are (somewhat unfortunately) plenty of ways to that.\n",
    "\n",
    "We recommend the following approach:\n",
    "\n",
    "  - First use `seaborn` to produce the scatter plot.\n",
    "  - Next get a range of predictor values from the plot's x-axis.\n",
    "  - Then use the `matplotlib` `plot()` function to overlay the prediction curve of the fitted model.\n",
    "  \n",
    "This approach might seem a bit heavy-handed for a linear model (it plots line segments between many points on the line, while only two are necessary). But it does have the advantage that it works with *any* model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x='lstat', y='medv', data=boston)\n",
    "xs = np.linspace(*ax.get_xlim(), 100)\n",
    "ax.plot(xs, model_fit.predict({'lstat': xs}), color='C1', lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have modified the colour and width of the line. The colour name `C1` refers to the second colour in the default colour cycle. We highly recommend to stick to the colours in the default colour cycle; they were selected for good reasons!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Regression Visualisation\n",
    "\n",
    "If we are not interested in all the statistics and flexibility `statsmodels` provides, we can use `seaborn`'s built-in regression plot facility. This is useful to have a quick look but lacks a lot of the additional information provided by a fitted model. In particular, this does not allow us to compute predictions from future data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(x='lstat', y='medv', data=boston,\n",
    "                 line_kws={'color': 'C1', 'lw': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `seaborn` also draws the confidence interval around the predictions as a shaded area. We will look at how to retrieve this information from our fitted model next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuals & Hat-values\n",
    "\n",
    "We use the `get_influence()` method to get access to a host of useful quantities, including residuals, studentised residuals and hat-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = model_fit.get_influence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(model_fit.predict(), influence.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studentised residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(model_fit.predict(), influence.resid_studentized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual plots suggest that there some non-linearity in the data. We can can get *leverage* statistics by accessing the `hat_matrix_diag` property of the `influence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(boston.index, influence.hat_matrix_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence.hat_matrix_diag.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `argmax()` method of `numpy` arrays gives us the *index* of the maximum value in the array. In this case it tells us which *observation* has the largest leverage statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the Fit Results with Confidence Interval Boundaries\n",
    "\n",
    "Our goal is to make a graph with a scatter plot and overlay the line resulting from the fit together with the 95% confident interval boundary lines.\n",
    "\n",
    "We recommend the following approach:\n",
    "\n",
    "  - First use `seaborn` to produce the scatter plot.\n",
    "  - Next get a range of predictor values from the plot's x-axis.\n",
    "  - Then use the `matplotlib` `plot()` function to overlay the predicted curve of the fitted model.\n",
    "  - Then use the `matplotlib` `fill_between()` function to overlay the confidence interval boundaries.\n",
    "  \n",
    "This approach does have the advantage that it works with *any* model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x='lstat', y='medv', data=boston)\n",
    "xs = np.linspace(*ax.get_xlim(), 100)\n",
    "pred = model_fit.get_prediction({'lstat': xs}).summary_frame()\n",
    "ax.plot(xs, pred['mean'], color='C1', lw=2)\n",
    "lower = pred['mean_ci_lower']\n",
    "upper = pred['mean_ci_upper']\n",
    "ax.fill_between(xs, lower, upper, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
