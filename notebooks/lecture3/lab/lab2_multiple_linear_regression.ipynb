{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Statistical Learning, Lab 3.2\n",
    "\n",
    "# Multiple Linear Regression\n",
    "\n",
    "In the Python environment the most popular libraries for model fitting (and therefore linear regression) *sklearn* and *statsmodels*. The statsmodels library provides a R-style formula-based interface. We will mostly use this interface because it provides more flexibility and better parameter reporting. This has the additional advantage that it maps quite well onto the examples in the ISLR book.  \n",
    "\n",
    "\n",
    "  - [statsmodels documentation](https://www.statsmodels.org/stable/)\n",
    "  - [statsmodels formula interface](https://www.statsmodels.org/stable/example_formulas.html)\n",
    "  - [the formula mini language](https://patsy.readthedocs.io/en/latest/formulas.html#the-formula-language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from islpy import datasets\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set\n",
    "\n",
    "We use the `Boston` data set to demonstrate multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.Boston()\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Specification\n",
    "\n",
    "The `smf.ols()` function builds a statistical *model* prepared for fitting with *ordinary least squares* (ols). This is the type of fit explained in detail in the lecture.\n",
    "\n",
    "the syntax to use multiple regressors (variables, predictors, features...) is `y~x1+x2+x3`. As in the simple regression with one predictor, a constant term for the intercept is added automatically.\n",
    "\n",
    "The formula `medv~lstat+age` means we are using `lstat` and `age` as our predictors and `medv` as our dependent variable:\n",
    "\n",
    "$$ \\mathrm{medv} = \\beta_0 + \\beta_1 \\mathrm{lstat} + \\beta_2 \\mathrm{age}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula='medv~lstat+age', data=boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the Model\n",
    "\n",
    "We *fit* the model to the data by calling the `fit()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Result Summary\n",
    "\n",
    "We can get a comprehensive summary using the `summary()` method. Now we get the results for all three $\\beta$ coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specific Summary Tables\n",
    "\n",
    "We can also select a specific table from the summary. For example the fitted coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Result Parameters\n",
    "\n",
    "Or we can retrieve only the fitted parameters ($\\beta_0$ = *intercept*, $\\beta_1$ = *lstat*) as a pandas series using the `params` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Intervals\n",
    "\n",
    "The 95% confidence intervals for the coefficients can be retrieved via the `conf_int()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising the Fit Results\n",
    "\n",
    "With two predictors we can visualise the data and the fit result in a 3D plot. The `seaborn` library does not provide 3D plotting facilities. There is a good reason for that: it is very hard to make informative 3D charts. Most of the time it is much better to think of a good way to visualise the data in 2D.\n",
    "\n",
    "That said, we want to give at least one example of a 3D chart. Our approach is similar to the one variable case:\n",
    "\n",
    "  - First produce a 3D scatter plot.\n",
    "  - Next get a range of predictor values from the plot's x- and y-axis and compute all predictions on a 2D grid.\n",
    "  - Then use the `plot_surface()` method to overlay the prediction plane of the fitted model.\n",
    "  \n",
    "Like in the one variable case, this approach might seem a bit heavy-handed for a linear model (it plots surface segments between many points on the grid, while only very few are necessary). But again it does have the advantage that it works with *any* model!\n",
    "\n",
    "In particular this also works for the confidence level surfaces which are *not* planes.\n",
    "\n",
    "What follows is quite a bit of code; making reasonably looking 3D plots is a bit of work. We include a number of different features in this chart so you have a reference to come back to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import cm\n",
    "sns.reset_defaults()\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = axes3d.Axes3D(fig)\n",
    "\n",
    "# 3D scatter plot of the raw data\n",
    "ax.scatter(boston.lstat, boston.age, boston.medv)\n",
    "\n",
    "# prepare point grids from the ranges of the scatter plot\n",
    "xs = np.linspace(*ax.get_xlim(), 100)\n",
    "ys = np.linspace(*ax.get_ylim(), 100)\n",
    "xv, yv = np.meshgrid(xs, ys, copy=False)\n",
    "zv = np.zeros((ys.size, xs.size))\n",
    "lv = np.zeros((ys.size, xs.size))\n",
    "uv = np.zeros((ys.size, xs.size))\n",
    "\n",
    "# compute predictions and CI bounds for the rows in the point grids\n",
    "for idx, y in enumerate(yv):\n",
    "    pred = model_fit.get_prediction({'lstat': xs, 'age': y}).summary_frame()\n",
    "    zv[idx] = pred['mean']\n",
    "    lv[idx] = pred['mean_ci_lower']\n",
    "    uv[idx] = pred['mean_ci_upper']\n",
    "\n",
    "# plot the prediction & CI boundary surfaces\n",
    "ax.plot_surface(xv, yv, zv, alpha=0.4)\n",
    "ax.plot_surface(xv, yv, lv, alpha=0.2, color='C1')\n",
    "ax.plot_surface(xv, yv, uv, alpha=0.2, color='C1')\n",
    "\n",
    "# add contour plot of the CI width to the bottom of the figure\n",
    "ax.contourf(xv, yv, uv-lv,\n",
    "            zdir='z',\n",
    "            offset=ax.get_zlim()[0],\n",
    "            levels=30,\n",
    "            antialiased=True,\n",
    "            cmap=cm.Oranges)\n",
    "\n",
    "# set figure title and axes labels\n",
    "ax.set_title('Linear regression on Boston housing data: medv ~ lstat + age')\n",
    "ax.set_xlabel('lstat')\n",
    "ax.set_ylabel('age')\n",
    "ax.set_zlabel('medv')\n",
    "\n",
    "# specify viewing angle\n",
    "ax.view_init(15, -70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks cool, but that's a bad reason to do it. Choosing a good viewing angle and the right surface transparencies can be a bit tricky. You can waste a lot of time (and CPU cycles) on this kind of thing. \n",
    "\n",
    "Obviously, once we use more than two predictors, this approach to visualisation won't work anymore. You can play tricks with colour coding and so on. But you can do that in 2D as well and the results will be much more readable!\n",
    "\n",
    "The bottom line is: __*don't make 3D charts unless you absolutely have to*__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 2D projection plots instead. This idea works for any number of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4.5))\n",
    "\n",
    "ax1 = sns.scatterplot(x='lstat', y='medv', data=boston, ax=ax1)\n",
    "ax2 = sns.scatterplot(x='age', y='medv', data=boston, ax=ax2)\n",
    "\n",
    "lstat = np.linspace(*ax1.get_xlim(), 100)\n",
    "age = np.linspace(*ax2.get_xlim(), 100)\n",
    "pred = model_fit.get_prediction({'lstat': lstat, 'age': age}).summary_frame()\n",
    "lower = pred['mean_ci_lower']\n",
    "upper = pred['mean_ci_upper']\n",
    "\n",
    "ax1.plot(lstat, pred['mean'], color='C1', lw=2)\n",
    "ax1.fill_between(lstat, lower, upper, alpha=0.3)\n",
    "ax2.plot(age, pred['mean'], color='C1', lw=2)\n",
    "ax2.fill_between(age, lower, upper, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interlude: Utility Functions & Modules\n",
    "\n",
    "This is Python, so we can wrap repetitive task in functions. Functions (like any Python object) can be defined in notebook code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fitted_model(fitted_model, var_name, data=None,\n",
    "                      ax=None, points=100, scolor='C0', fcolor='C1', alpha=0.3):\n",
    "    \"\"\"Make a scatter plot and overlay fit result.\"\"\"\n",
    "\n",
    "    model = fitted_model.model\n",
    "\n",
    "    if data is None:\n",
    "        data = pd.DataFrame(model.exog, columns=model.exog_names)\n",
    "        data[model.endog_names] = model.endog\n",
    "\n",
    "    xs = pd.DataFrame()\n",
    "    for name in model.exog_names:\n",
    "        try:\n",
    "            xs[name] = np.linspace(data[name].min(), data[name].max(), points)\n",
    "        except KeyError:\n",
    "            xs[name] = np.ones(points)  # presumably the intercept\n",
    "    \n",
    "    pred = fitted_model.get_prediction(xs).summary_frame()\n",
    "    x = xs[var_name]\n",
    "    y = pred['mean']\n",
    "    cil = pred['mean_ci_lower']\n",
    "    ciu = pred['mean_ci_upper']\n",
    "\n",
    "    ax = sns.scatterplot(x=var_name, y=model.endog_names,\n",
    "                         data=data, ax=ax, color=scolor)\n",
    "    ax.plot(x, y, color=fcolor, lw=2)\n",
    "    ax.fill_between(x, cil, ciu, color=fcolor, alpha=alpha)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reproduce the two plots using the new utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4.5))\n",
    "plot_fitted_model(model_fit, 'lstat', ax=ax1)\n",
    "plot_fitted_model(model_fit, 'age', ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be useful in the future. We create a module in the `utils/` directory that we can import later at any time.\n",
    "\n",
    "We have to tell Jupyter/Python to look for modules in the `utils/` directory. This can also be configured centrally (in fact we have done this for you on `student` account on the VM). But we want to show you how to do it in a notebook explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../utils')\n",
    "import plots\n",
    "help(plots.plot_fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many Variables\n",
    "\n",
    "Back on topic, we now want to perform a linear regression on *all* the variables in the `Boston` data set. It would be tedious to type in all variable names. Since this is a common problem, it is unfortunate that the formula mini language does not provide a shortcut for this (R does).\n",
    "\n",
    "Fortunately, it is not too hard to construct the formula using string operations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'medv~' + '+'.join(boston.columns.drop('medv'))\n",
    "model = smf.ols(formula=formula, data=boston)\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WARNING:\n",
    "\n",
    "The underlying formula parser has some limitations. Formulas with more than a few hundred terms can not be parsed by the current implementation.\n",
    "\n",
    "In these situations we can build our model as [documented here](https://patsy.readthedocs.io/en/latest/expert-model-specification.html).\n",
    "\n",
    "We give an example that replicates the formula-based approach used above.  Essentially, we explicitly build the terms and expressions that the parse of a string formula would provide -- we just took out the middle man. This will work for a large number of features without problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from patsy import ModelDesc, Term, LookupFactor, dmatrices\n",
    "import statsmodels.api as sm\n",
    "\n",
    "lhs = [Term([LookupFactor('medv')])]\n",
    "rhs = [Term([])]  # the intercept\n",
    "for name in boston.columns.drop('medv'):\n",
    "    rhs.append(Term([LookupFactor(name)]))\n",
    "md = ModelDesc(lhs, rhs)\n",
    "y, xs = dmatrices(md, boston, return_type='dataframe')\n",
    "model = sm.OLS(y, xs)\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also completely bypass the high-level interface provided by `patsy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston['medv']\n",
    "xs = boston.drop(columns='medv')\n",
    "xs['Intercept'] = 1\n",
    "model = sm.OLS(y, xs)\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fine in this case. If some of our variables should be treated are class variables (categories) things quickly become complicated, though. In these cases we want to use `patsy` or the formula API because they support categorical variables.\n",
    "\n",
    "In summary:\n",
    "\n",
    "  - Use the formula API to define models whenever you can. It is concise and expressive.\n",
    "  - Use `patsy` to explicitly build *design matrices* if you need support for class variables on data sets with many ($\\sim\\mathcal{O}(1000)$) features.\n",
    "  - Build the matrices yourself if you have a large number ($\\sim\\mathcal{O}(1000)$) of simple quantitative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access individual quantities from the fit result. For example, the RSE and $R^2$.\n",
    "\n",
    "The `statsmodels` documentation provides the [full list](https://www.statsmodels.org/devel/generated/statsmodels.regression.linear_model.RegressionResults.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RSE: {np.sqrt(model_fit.scale):.4f}')\n",
    "print(f'R^2: {model_fit.rsquared:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance Inflation Factors\n",
    "\n",
    "To compute *variance inflation factors* we need to import a function from `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vifs = {n: variance_inflation_factor(model.exog, i) for i, n in zip(\n",
    "    range(model.exog.shape[1]), model.exog_names)}\n",
    "vifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the Model\n",
    "\n",
    "The $p$-values of `age` and `indus` are rather high. We'd therefore like to remove them from the model and update the fit.\n",
    "\n",
    "There are several ways to do that. We will simply create a new model with the `age` and `indus` variables removed, as is recommended by the `statsmodels` [documentation](https://www.statsmodels.org/dev/pitfalls.html).\n",
    "\n",
    "This approach might be problematic in terms of performance (as in CPU time) for large data sets. This is not easy to address and we won't cover it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'medv~' + '+'.join(boston.columns.drop(['medv', 'age', 'indus']))\n",
    "model = smf.ols(formula=formula, data=boston)\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we make couple of projection plots again; this time using the *imported* plot function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4.5))\n",
    "plot_fitted_model(model_fit, 'lstat', ax=ax1)\n",
    "plot_fitted_model(model_fit, 'dis', ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
