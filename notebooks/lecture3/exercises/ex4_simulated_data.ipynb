{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Statistical Learning, Exercise 3.4\n",
    "\n",
    "__Please do yourself a favour and only look at the solutions after you honestly tried to solve the exercises.__\n",
    "\n",
    "# Simulated Data\n",
    "\n",
    "We will simulate a data set and investigate how things change with varying parameters of the simulation. This allows us to evaluate our models against the simulation truth.\n",
    "\n",
    "We will use `numpy`'s random generator facilities for the simulation. If you want reproducible results you should set the random seed explicitly like this at the beginning (the actual seed value does not matter):\n",
    "\n",
    "```python\n",
    "np.random.seed(seed=123)\n",
    "```\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from islpy import datasets, utils, lmplots\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Simulate the Feature\n",
    "\n",
    "Using the `np.random.normal()` function, create a a vector `x` containing a 100 observations drawn from a $N(0, 1)$ distribution. This represents the feature $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=123)  # we only need to do this once at the start\n",
    "x = np.random.normal(size=100)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Simulate the Noise\n",
    "\n",
    "Using the `np.random.normal()` function, create a a vector `eps` containing a 100 observations drawn from a $N(0, 0.25)$ distribution. That is, a normal distribution with mean 0 and standard deviation 0.25. This represents the noise $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.random.normal(0, 0.25, size=100)\n",
    "eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Simulate the Response\n",
    "\n",
    "Using the vectors `x` and `eps`, generate a vector `y` according to the following model:\n",
    "\n",
    "$$ Y = -1 + 0.5 X + \\epsilon $$\n",
    "\n",
    "This represents the response $Y$. What is the length of the vector `y`? What are the values of $\\beta_0$ and $\\beta_1$ in this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = -1 + 0.5 * x + eps \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.size, y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta_0 = -1$ and $\\beta_1 = 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Plot the y-x Relationship\n",
    "\n",
    "Create a scatter plot of `y` versus `x`. Comment on what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is clearly a linear relationship in the simulated data. The simulated noise is also clearly visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Linear Model Fit\n",
    "\n",
    "Fit at least squares model to the data with `y` as the response and `x` as the predictor. Comment on what you observe. How are the estimated parameters $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ compare to the true values $\\beta_0$ and $\\beta_1$?\n",
    "\n",
    "Hint: you can do this directly with `sm.OLS()` but creating a data frame first and using `smf.ols()` might be more convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'y': y, 'x':x})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = smf.ols('y~x', data).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model fits the data very well. The estimated parameters a close to the true parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Plotting Estimate & Truth\n",
    "\n",
    "Make a scatter plot of `y` versus `x` and overlay the *population regression line* and the *least squares line*. Create an appropriate legend by using labels and the `legend()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x='x', y='y', data=data)\n",
    "x = np.linspace(*ax.get_xlim(), 10)\n",
    "y_true = -1 + 0.5 * x\n",
    "y_fit = lm.predict({'x': x})\n",
    "ax.plot(x, y_true, label='truth')\n",
    "ax.plot(x, y_fit, color='C1', label='fit')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Quadratic Term\n",
    "\n",
    "Now fit a model that uses `x` and `x`${}^2$ as the predictors. Does the quadratic term improve the model fit? Explain you answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2 = smf.ols('y~x+I(x**2)', data).fit()\n",
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, the quadratic term does *not* improve the model fit; the $F$-statistic is significantly lower. Also the $p$-value of the quadratic term is very high. This is of course expected, because the data has a truly linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
